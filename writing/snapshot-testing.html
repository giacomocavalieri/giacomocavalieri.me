<!doctype html>
<html lang="en"><head><title>TODO AND ABSTRACT</title><meta charset="utf-8"><meta content="width=device-width, initial-scale=1.0, viewport-fit=cover" name="viewport"><link href="https://giacomocavalieri.me/feed.xml" rel="alternate" title="giacomocavalieri.me posts feed" type="application/rss+xml"><link href="favicon.ico" rel="icon" type="image/x-icon"><meta content="Giacomo Cavalieri" property="og:site_name"><meta content="TODO AND ABSTRACT" property="og:title"><meta content="website" property="og:type"><meta content="https://giacomocavalieri.me/imgs/og-preview-image.jpg" property="og:image"><meta content="TODO" property="og:description"><meta content="TODO" name="description"><link href="/style-6.css" rel="stylesheet"><script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/languages/diff.min.js"></script><script src="/highlightjs-gleam.js"></script><script>hljs.highlightAll();</script></head><body class="stack-l"><ol aria-label="Breadcrumb" class="breadcrumb"><li><a href="/">home</a></li><li><a href="/writing.html" style="view-transition-name:writing-animation;">writing</a></li><li><h2 aria-current="page" data-crumb="block">TODO AND ABSTRACT</h2></li></ol><main class="stack article"><section class="stack"><p>Writing tests is boring.
Even worse, maintaining tests is boring <em>and</em> error prone.
The tragedy is they&#39;re also one of the most valuable pieces of code we could
write.</p><p>So let me show you a fun technique to add to your testing toolbox that can make
writing and maintaining tests a whole lot more pleasant.
This technique is applicable everywhere and to prove it we&#39;ll go through
real-world examples ranging from CLIs, to compilers written in Rust, to…
web animations!</p></section><section class="stack"><span><h2 id="the-problem" style="display:inline;"><span><a class="anchor" href="#the-problem">#</a> </span>The problem</h2></span><p>Say you&#39;re writing a command line application (CLI), maybe it&#39;s just a little
internal tool for your company to be used to automate some tedious chores, or
maybe it&#39;s a cool open source project.
What&#39;s the most important part of this application?
<em>The help text!</em>
That&#39;s what users will look at when they&#39;re lost, so it&#39;s crucial to get it
right.
Does this ring a bell?
Since it&#39;s so important we should be testing it:</p><pre><code class="not-prose language-gleam hljs" data-lang="gleam">pub fn help_text_test() {
  assert cli.help_text() == &quot;
usage: lucysay [-m message] [-f file]

  -m, --message  the message to be printed
  -f, --file     a file to read the message from
  -h, --help     show this help text
&quot;
}
</code></pre><p>We&#39;re checking the help text string conforms to an expected message, since we&#39;re
writing a regular unit test assertion there&#39;s no escaping it: we have to type
that in full.</p><p>What&#39;s worse is, if the help text changes (say we&#39;re shipping a v2 with more
flags and features) we&#39;ll have to go through that literal string and manually
edit it to make sure the test goes back to passing.
This is quite the tedious chore.
Writing and maintaining these kind of tests, with wordy assertions, is never
fun: it&#39;s a boring, repetitive, and error-prone process.</p></section><section class="stack"><span><h2 id="snapshot-testing-to-the-rescue" style="display:inline;"><span><a class="anchor" href="#snapshot-testing-to-the-rescue">#</a> </span>Snapshot testing to the rescue</h2></span><p>Here&#39;s were snapshot testing comes into play.
The elevator pitch is simple: <em>you can focus on writing tests, and the snapshot
testing library will take care of the expected values automatically.</em></p><p>What does this look like in practice? Here&#39;s a snapshot test:</p><pre><code class="not-prose language-gleam hljs" data-lang="gleam">// In these examples we&#39;ll use the birdie library.
// You can add it to a gleam project by running
// `gleam add birdie --dev`
import birdie

pub fn help_text_test() {
  cli.help_text()
  |&gt; birdie.snap(title: &quot;testing the help text&quot;)
}
</code></pre><p>The function under test is still the same, but this time we&#39;re passing its
result to the <code>birdie.snap</code> function (don&#39;t worry about the title for now,
we&#39;ll get to that later).</p><p>This looks a bit magical: the expected value is nowhere to be seen, so how can
the library know when the test should fail? What happens if we run the test?
Let&#39;s try it!</p><div><pre><code data-highlighted='yes' class='not-prose language-shell'><span class='hljs-comment'>> gleam test</span>

<span class='hljs-shell-error'>panic</span> test/example_test.gleam:9
 <span class='hljs-shell-info'>test</span>: example_test.usage_text_test
 <span class='hljs-shell-info'>info</span>: Birdie snapshot test failed

Finished in 0.006 seconds
<span class='hljs-shell-error'>1 tests, 1 failures</span></code>
</pre></div><p>Not that exciting, the test is failing.
But we&#39;ll also see some new output along the failing test, this is where the
magic happens:</p><div><pre><code data-highlighted='yes' class='not-prose language-shell'>── new snapshot ────────────────────────────────────────────
  <span class='hljs-shell-info'>title</span>: testing the help text
  <span class='hljs-shell-info'>hint</span>: <span class='hljs-shell-warning'>run `gleam run -m birdie` to review the snapshots</span>
────────┬───────────────────────────────────────────────────
      <span class='hljs-shell-new'>1 + usage: lucysay [-m message] [-f file]
      2 +
      3 +  -m, --message  the message to be printed
      4 +  -f, --file     a file to read the message from
      5 +  -h, --help     show this help text</span>
────────┴───────────────────────────────────────────────────</code></pre></div><p>As the test fails it shows us the actual output produced by the function.
If we read the hint we realise that a human needs to be in the loop: we have to
<em>review</em> the snapshot.
Let&#39;s follow the library&#39;s hint and review it:</p><div><pre><code data-highlighted='yes' class='not-prose language-shell'><span class='hljs-comment'>> gleam run -m birdie</span>

Reviewing <span class='hljs-shell-warning'>1st</span> out of <span class='hljs-shell-warning'>1</span>

── new snapshot ────────────────────────────────────────────
  <span class='hljs-shell-info'>title</span>: testing the help text
  <span class='hljs-shell-info'>file</span>: ./test/cli.gleam
────────┬───────────────────────────────────────────────────
       <span class='hljs-comment'>... here you'll see the snapshot from earlier</span>
────────┴───────────────────────────────────────────────────

  <span class='hljs-shell-new'>a</span> accept     accept the new snapshot
  <span class='hljs-shell-error'>r</span> reject     reject the new snapshot
  <span class='hljs-shell-warning'>s</span> skip       skip the snapshot for now
  <span class='hljs-shell-info'>d</span> hide diff  toggle snapshot diff</code></pre></div><p>We can read the content and see that it is exactly what we want, listing all the
options, and with no typos.
We accept the snapshot.
Now every time we run the tests, they will succeed… given the output of the
function doesn&#39;t change.</p><p>What&#39;s happening under the hood is unremarkably simple: the snapshot testing
library, once we accept the snapshot, saves its content to a file and checks
that the function will always produce that value.
If the output changes, the test will fail and we&#39;ll have to review the snapshot
again.</p><p>You can actually try the whole workflow for yourself here, just follow the hints
and type away!</p><div><div id="terminal"></div>
<script src="/js/birdie_terminal.js" type="module"></script></div></section><section class="stack"><span><h3 id="it-s-like-vcs-for-your-tests" style="display:inline;"><span><a class="anchor" href="#it-s-like-vcs-for-your-tests">#</a> </span>It&#39;s like VCS for your tests</h3></span><p>The nice upside about dealing with changing assertions is that the snapshot
testing library can be incredibly helpful when something changes.
For example, <a href="https://github.com/giacomocavalieri/birdie"><code>birdie</code></a> (the library
I&#39;m using here) will show you an informative diff view, much like a version
control system:</p><div><pre><code data-highlighted='yes' class='not-prose language-shell'>── mismatched snapshot ─────────────────────────────────────
  <span class='hljs-shell-info'>title</span>: testing the help text
  <span class='hljs-shell-info'>hint</span>: <span class='hljs-shell-warning'>run `gleam run -m birdie` to review the snapshots</span>
────────┬───────────────────────────────────────────────────
 <span class='hljs-shell-error'>1      - usage: lucysay [-m message] [-f file]</span>
      <span class='hljs-shell-new'>1 + usage: lucysay [-m message]</span>
      <span class='hljs-shell-new'>2 +   prints a cute message to standard output</span>
      <span class='hljs-comment'>3</span> │
      <span class='hljs-comment'>4</span> |  <span class='hljs-comment'>-m, --message  the message to be printed</span>
 <span class='hljs-shell-error'>4      -  -f, --file     a file to read the message from</span>
      <span class='hljs-comment'>5</span> |  <span class='hljs-comment'>-h, --help     show this help text</span>
────────┴───────────────────────────────────────────────────</code></pre></div><p>This is a really nice developer experience, we can see at a glance what has
changed and review it. And the best thing is we&#39;ve already been successfully
using this workflow for years with version control systems like <code>git</code> and
<a href="https://www.jj-vcs.dev/latest/"><code>jj</code></a>.
We know how all of this works, it feels familiar:</p><ul><li><section class="stack"><p>Something has changed, so it needs a review</p></section></li><li><section class="stack"><p>It looks ok, we can accept it and go on with our day</p></section></li><li><section class="stack"><p>It looks bad, we have to figure out if the change is wanted at all, or what
the cause of the bug might be</p></section></li></ul><p>Nowhere in this process we had to go through the assertions and update them
manually.
We can finally start focusing on our tests without being slowed down by managing
explicit assertions.</p></section><section class="stack"><span><h2 id="but-what-about-non-strings" style="display:inline;"><span><a class="anchor" href="#but-what-about-non-strings">#</a> </span>But what about non-strings?</h2></span><p>I hear you. With my first example I have cheated a bit: the function we were
testing already produces a string that can be easily snapshotted and diffed.
But the functions we want to test in the real world rarely do that!
We might have to deal with lists, dictionaries, complex objects, strange
collections of data.
What then?</p><p><em>Turn them into strings.</em></p><p>Do we have to come up with a <code>to_string</code> function for each piece of data we want
to test?</p><p><em>Yes! And that&#39;s good actually!</em></p><p>It&#39;s easy to fall victim to the idea of turning each piece of data into a string
using some magic one-size-fit-all <code>to_string</code> function.
But being intentional about each snapshot&#39;s content is what actually makes or
breaks this testing technique.
Working with the <a href="https://github.com/gleam-lang/gleam">Gleam compiler</a> I ran
into a great example of how much of a difference a good snapshot test can
actually make.</p><p>The Gleam compiler is a big piece of software written in Rust, it&#39;s also quite
thoroughly tested with over 5000 unit tests.
More than 3000 are actually snapshot tests (so if you&#39;re wondering if snapshot
testing can actually work in big numbers… it absolutely can)!</p><p>The piece of the Gleam codebase I will be focusing on is the Language Server
implementation.
I was looking at some snapshot tests meaning to check that hovering tooltips
actually worked.</p><blockquote class="stack"><p>The Language Server Protocol allows to display little tooltips when hovering
over specific portions of code. It&#39;s what shows you the documentation of a
function once you go over it with your cursor; or what shows you the inferred
type of a variable.</p><pre><code class="not-prose language-gleam hljs" data-lang="gleam">pub fn main() -&gt; Nil {
  let a_variable = 11
  //  ^^^ If I put my cursor over here I&#39;m expecting
  //      a helpful tooltip to tell me the type of
  //      the variable, an `Int` in this case.
}
</code></pre><p>
It&#39;s really useful, so we have to make sure we&#39;re displaying the correct
information and, crucially, that it is positioned correctly over the hovered
element.</p></blockquote><p>The Language Server produces some complex data structure with all the
information needed to render the tooltip by the IDE, that&#39;s what we will be
testing.
What we ended up doing at first, for lack of better ideas, is we snapshotted
the entire data structure turning it into a string using a default display
function. This is the test:</p><pre><code class="not-prose language-gleam hljs" data-lang="gleam">pub fn hovering_variable_test() {
  hover(over: find_position_of(&quot;a_variable&quot;), code: &quot;
    pub fn main() -&gt; Nil {
      let a_variable = 11
      Nil
    }
  &quot;)
  |&gt; hover_data_to_string
  |&gt; birdie.snap(title: &quot;hovering over a variable shows its type&quot;)
}
</code></pre><p>And here&#39;s what the snapshot would look like:</p><div><pre><code data-highlighted='yes' class='not-prose language-shell'>── new snapshot ────────────────────────────────────────────
  <span class='hljs-shell-info'>title</span>: hovering over a variable shows its type
  <span class='hljs-shell-info'>hint</span>: <span class='hljs-shell-warning'>run `gleam run -m birdie` to review the snapshots</span>
────────┬───────────────────────────────────────────────────
      <span class='hljs-shell-new'>1 + Hover(
      2 +   range: Some(Range(start: 24, end: 33)),
      3 +   contents: Scalar(
      4 +     String("```gleam\nInt\n```"),
      5 +   ),
      6 + )</span>
────────┴───────────────────────────────────────────────────</code></pre></div><p>Let me ask you: is this a good snapshot test?
It certainly contains all the information we care about, and it&#39;s plenty enough
to figure out if the implementation is correct.</p><p><em>But does it make it easy to see the implementation is correct?</em></p><p>The range over which we display the tooltip might be wrong, and I wouldn&#39;t be
any wiser!
What I need to do is to painfully go and count the bytes in the original string
to make sure it is actually hovering the whole variable.
We&#39;ve replaced a painful unit test assertion with a painful-to-review snapshot!</p><p>When figuring out how to produce a snapshot, putting care into its string format
is crucial to make testing simple and fun.
In this example, this is the look I ended up implementing:</p><div><pre><code data-highlighted='yes' class='not-prose language-shell'>── new snapshot ────────────────────────────────────────────
  <span class='hljs-shell-info'>title</span>: hovering over a variable shows its type
  <span class='hljs-shell-info'>hint</span>: <span class='hljs-shell-warning'>run `gleam run -m birdie` to review the snapshots</span>
────────┬───────────────────────────────────────────────────
      <span class='hljs-shell-new'>1 + pub fn main() -> Nil {
      2 +   let a_variable = 11
      3 +       ↑▔▔▔▔▔▔▔▔▔
      4 +   Nil
      6 + }
      5 +
      6 + ----- Hover content:
      7 + ```gleam
      8 + Int
      9 + ```</span>
────────┴───────────────────────────────────────────────────</code></pre></div><p>This is what I call a fun snapshot.
Looking at it we can see at a glance that the tooltip is perfectly aligned with
the variable being hovered, and its content is also rendered nicely below.</p><p>I cannot understate how much time having nice-to-read snapshots like this one
has saved me, Louis, and Surya when reviewing new code being contributed to the
Gleam compiler.
Heck, I&#39;d go so far to say it&#39;s actually fun to write tests and be confronted
with such nice and visual output!</p></section><section class="stack"><span><h2 id="your-imagination-s-the-limit" style="display:inline;"><span><a class="anchor" href="#your-imagination-s-the-limit">#</a> </span>Your imagination&#39;s the limit</h2></span><p>Hopefully, now you can get a sense for how powerful and malleable this can
actually be.
Ever since publishing my own snapshot testing library, I&#39;ve been amazed by the
creativity with which people have used it.</p></section><section class="stack"><span><h3 id="testing-tricky-math-made-easy" style="display:inline;"><span><a class="anchor" href="#testing-tricky-math-made-easy">#</a> </span>Testing tricky math made easy</h3></span><p>This last example was shown to me by Hayleigh, a dear friend working on a
<a href="https://lustre.build">cool frontend framework</a>.
As part of a component library, Hayleigh also implemented some
<a href="https://en.wikipedia.org/wiki/Inbetweening#Digital_animation">tweening functions</a>.
A tweening function is what underpins all kind of animations, and based on the
specific function we&#39;re using we can get all sorts of movements: linear,
with ease-in and ease-out, cubic, and so on…</p><p>At its core a tweening function is pretty straightforward (even though the math
involved is certainly not): you take a value as input, the minimum and maximum
ranges for that value, and return a new interpolated value:</p><pre><code class="not-prose language-gleam hljs" data-lang="gleam">fn tween_cubic_in_out(
  t value: Float,
  between min: Float,
  and max: Float
) -&gt; Float {
  todo as &quot;some tricky math in here...&quot;
}
</code></pre><p>If you&#39;ve already done some frontend development you might already have an
intuition for what kind of movement this interpolation function will result in.
But you can also play around with it and see for yourself down here.
Try and move the slider to see how the interpolated value changes:</p><div><pre id="curve"></pre>
<script src="/js/curve_in_out.js" type="module"></script></div><p>The math in there can be quite tricky and easy to get wrong, so of course we
have to test that the implementation is correct.
If we were to write a regular unit test we might check the expected output for
some known values:</p><pre><code class="not-prose language-gleam hljs" data-lang="gleam">pub fn tween_cubic_in_out_test() {
  assert tween_cubic_in_out(0.0, between: 0.0, and: 1.0) == 0.0
  assert tween_cubic_in_out(0.5, between: 0.0, and: 1.0) == 0.5
  assert tween_cubic_in_out(0.7, between: 0.0, and: 1.0) == 0.89
}
</code></pre><p>But is this a good test? Imagine someone saw your cool library and decided to
contribute with a new animation <code>tween_sine_in_out</code>, they also added new tests,
how nice of them!</p><pre><code class="not-prose language-gleam hljs" data-lang="gleam">pub fn tween_sine_in_out_test() {
  assert tween_sine_in_out(0.0, between: 0.0, and: 1.0) == 0.0
  assert tween_sine_in_out(0.5, between: 0.0, and: 1.0) == 0.7
  assert tween_sine_in_out(0.7, between: 0.0, and: 1.0) == 0.9
}
</code></pre><p>Does looking at this test give you confidence that the implementation of this
new function is correct? Not really. You&#39;d have to:</p><ul><li><section class="stack"><p>Carefully check the implementation is right</p></section></li><li><section class="stack"><p>Or carefully do the math yourself and verify the asserted values are actually
correct</p></section></li></ul><p>At a glance, this test is <em>not telling me much</em> about the correctness of the
tested function. Reviewing it is tedious work.
So how can snapshot tests help us here?
Can we really use them for something this abstract?
<em>You kind of already have!</em>
Playing around with a slider and <em>looking</em> at the described shape easily gives
us a good idea of how the tweening function will behave, so why not do that for
our tests?
What Hayleigh came up with looks like this:</p><pre><code class="not-prose language-gleam hljs" data-lang="gleam">pub fn tween_cubic_in_out_test() {
  tween_cubic_in_out
  |&gt; plot_function
  |&gt; birdie.snap(title: &quot;cubic tween with in and out easing&quot;)
}
</code></pre><p>What does the snapshot look like?</p><div><pre><code data-highlighted='yes' class='not-prose language-shell'>── new snapshot ────────────────────────────────────────────
  <span class='hljs-shell-info'>title</span>: cubic tween with in and out easing
  <span class='hljs-shell-info'>hint</span>: <span class='hljs-shell-warning'>run `gleam run -m birdie` to review the snapshots</span>
────────┬───────────────────────────────────────────────────
      <span class='hljs-shell-new'>1 +                               ◍◍◍◍◍◍
      2 +                             ◍◍
      3 +                           ◍◍
      4 +                          ◍
      5 +                         ◍
      6 +
      7 +                       ◍
      8 +
      9 +                      ◍
     10 +
     11 +                     ◍
     12 +
     13 +                    ◍
     14 +
     15 +                   ◍
     16 +
     17 +
     18 +                  ◍
     19 +
     20 +                 ◍
     21 +
     22 +                ◍
     23 +
     24 +               ◍
     25 +
     26 +              ◍
     27 +
     28 +            ◍
     29 +           ◍
     30 +         ◍◍
     31 +       ◍◍
     32 + ◍◍◍◍◍◍</span>
────────┴───────────────────────────────────────────────────</code></pre></div><p>How brilliant is that?
You can easily see at a glance that this is a cubic curve that eases in and out
of its extremes.
I don&#39;t know about you but this test gives me much more confidence in the
correct working of the function, rather than having a bunch of random-looking
<code>Float</code>s scattered through my test suite.</p></section><section class="stack"><span><h2 id="effective-snapshot-testing" style="display:inline;"><span><a class="anchor" href="#effective-snapshot-testing">#</a> </span>Effective snapshot testing</h2></span><p>Now, before you start trying to converting all your tests into snapshots I&#39;d
like to share some insights on how to use this tool <em>effectively.</em></p></section><section class="stack"><span><h3 id="use-long-descriptive-titles" style="display:inline;"><span><a class="anchor" href="#use-long-descriptive-titles">#</a> </span>Use long descriptive titles</h3></span><p>Notice how snapshots require a title, that is what is shown you when you&#39;re
reviewing them.
And it&#39;s actually an important piece of the equation: it&#39;s telling you what to
look for.
If your snapshot is called <code>&quot;some test&quot;</code> it&#39;s not really easy to figure out what
you&#39;re looking at, isn&#39;t it?
On the other hand, if your snapshot title is
<code>&quot;the &#39;wibble&#39; variable is underlined&quot;</code>, you know exactly what should be
happening in the snapshot body and if the <code>wibble</code> variable is not underlined
you&#39;ll reject it.</p></section><section class="stack"><span><h3 id="keep-your-snapshots-small" style="display:inline;"><span><a class="anchor" href="#keep-your-snapshots-small">#</a> </span>Keep your snapshots small</h3></span><p>Unit tests have it easy.
It&#39;s in their name: they should be a self-contained, small unit.
The same goes for snapshot tests: <em>don&#39;t try and cram too much into a single snapshot.</em></p><p>That&#39;s for the same reason that we feel a sense of dread when someone asks our
review on a <code>+10293/-5011</code> pull request: it&#39;s a lot simpler to review many small
and well-defined snapshots rather than a single huge one… your colleagues will
thank you!</p><p>The exact size will vary, but a good rule of thumb is if your snapshot is 10/50
lines long it could be totally fine.
If it starts getting longer it might be a sign you have to refactor your test
(yes, tests need refactoring and love too), maybe you&#39;re trying to <em>assert way
too many things at once</em> and you could replace a single snapshot with a couple
of more focused ones.</p></section><section class="stack"><span><h3 id="don-t-overdo-it" style="display:inline;"><span><a class="anchor" href="#don-t-overdo-it">#</a> </span>Don&#39;t overdo it</h3></span><p>This is the most important one.
When we learn some new cool and shiny tool we think it&#39;s the next best thing
and want to use it everywhere.
But it&#39;s even more important knowing when <em>not</em> to use something.
As for snapshot testing:</p><ul><li><section class="stack"><p>If your assertions are simple</p></section></li><li><section class="stack"><p>If the tested data rarely ever changes</p></section></li><li><section class="stack"><p>If maintaining and evolving the test is not all that painful</p></section></li></ul><p>Then it might be the case that a regular unit test assertion is perfectly fine.</p></section><section class="stack"><span><h2 id="conclusions" style="display:inline;"><span><a class="anchor" href="#conclusions">#</a> </span>Conclusions</h2></span><p>Hopefully you now have a new tool to level up your testing game.
I think snapshot testing is criminally underused and has a kind of bad rep
because of badly misused it is in browser integration tests (by the way if you
want to learn more about UI testing,
<a href="https://www.youtube.com/watch?v=lnvmbzwIt94">this might be the talk for you</a>).</p><p>In my experience snapshot testing has been a life saver.
I now default to snapshot testing first and only in the cases mentioned above
I switch back to unit testing… and I&#39;ll never look back!</p><hr><p>Thank you so much for reading through this, and thanks to all the amazing people
who shared their feedback.</p><p>This has been lovingly written and coded entirely by a human: me!
It takes quite some time, and if you want to support me you can on
<a href="https://github.com/sponsors/giacomocavalieri">GitHub Sponsors.</a></p></section></main></body></html>